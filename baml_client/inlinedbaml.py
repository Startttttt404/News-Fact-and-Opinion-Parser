###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "../c:\\Users\\e109300\\Projects\\Agentic Design Lab\\baml_src\\clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\r\n\r\nclient<llm> GPT4o {\r\n  provider openai\r\n  options {\r\n    model \"gpt-4o\"\r\n    api_key env.OPENAI_API_KEY\r\n  }\r\n}\r\n\r\nclient<llm> GPT4oMini {\r\n  provider openai\r\n  options {\r\n    model \"gpt-4o-mini\"\r\n    api_key env.OPENAI_API_KEY\r\n  }\r\n}\r\n\r\nclient<llm> Sonnet {\r\n  provider anthropic\r\n  options {\r\n    model \"claude-3-5-sonnet-20240620\"\r\n    api_key env.ANTHROPIC_API_KEY\r\n  }\r\n}\r\n\r\n\r\nclient<llm> Haiku {\r\n  provider anthropic\r\n  options {\r\n    model \"claude-3-haiku-20240307\"\r\n    api_key env.ANTHROPIC_API_KEY\r\n  }\r\n}\r\n\r\nclient<llm> Fast {\r\n  provider round-robin\r\n  options {\r\n    // This will alternate between the two clients\r\n    strategy [GPT4oMini, Haiku]\r\n  }\r\n}\r\n\r\nclient<llm> Openai {\r\n  provider fallback\r\n  options {\r\n    // This will try the clients in order until one succeeds\r\n    strategy [GPT4o, GPT4oMini]\r\n  }\r\n}",
    "../c:\\Users\\e109300\\Projects\\Agentic Design Lab\\baml_src\\find_facts_and_opinions.baml": "enum ContentType{\r\n    FACT\r\n    OPINION\r\n}\r\n\r\nfunction IdentifyContentType(content: string) -> ContentType{\r\n    /// Uses gpt-4o-mini to decide if a string is a fact or opinion.\r\n    client \"openai/gpt-4o-mini\"\r\n    prompt #\"\r\n        Indentify if this is a fact or opinion.\r\n\r\n        {{ctx.output_format}}\r\n\r\n        {{_.role('user')}}\r\n        {{content}}\r\n    \"#\r\n}\r\n\r\n",
    "../c:\\Users\\e109300\\Projects\\Agentic Design Lab\\baml_src\\find_source.baml": "enum Source {\r\n    CNN\r\n    BBC\r\n    REDDIT\r\n    UNKNOWN\r\n}\r\n\r\nfunction IdentifySource(content: string) -> Source{\r\n    /// Uses gpt-4o-mini to try and find the source of a block of content. Will ere on the safe side.\r\n    client \"openai/gpt-4o-mini\"\r\n    prompt #\"\r\n        Identify where this article is from.\r\n\r\n        {{ctx.output_format}}\r\n\r\n        If you are not sure, say UNKNOWN\r\n        {{_.role('user')}}\r\n        {{content}}\r\n    \"#\r\n}",
    "../c:\\Users\\e109300\\Projects\\Agentic Design Lab\\baml_src\\generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.58.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
}

def get_baml_files():
    return file_map